{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 测试KITree不同超参的效果，使用'cicids_custom'和'toniot_custom'数据集，使用\"AE\",\"VAE\",\"Whisper\",'Whisper',\"IForest\",\"OCSVM\"作为black_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../../src/')\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from global_var import *\n",
    "from normalize import *\n",
    "from data_load import *\n",
    "from utils import *\n",
    "from AE import AutoEncoder\n",
    "from VAE import VAE\n",
    "import ExtBound\n",
    "import KITree\n",
    "import importlib\n",
    "from IBMMExtraction import *\n",
    "import utils as Utils\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from utils import evaluate_and_save_results_Hyperparameters\n",
    "\n",
    "importlib.reload(KITree)\n",
    "models = [\"AE\",\"VAE\",\"Whisper\",\"OCSVM\",\"IForest\"] \n",
    "\n",
    "datasets = {\n",
    "    'toniot_custom': [\n",
    "        'backdoor',\n",
    "        'ddos',\n",
    "        'dos',\n",
    "        'injection',\n",
    "        'mitm',\n",
    "        'password',\n",
    "        'runsomware',\n",
    "        'scanning',\n",
    "        'xss'\n",
    "    ]\n",
    "}\n",
    "\n",
    "max_levels = [5, 10, 15, 20, 25]\n",
    "n_beams = [2, 4, 6, 8, 10]\n",
    "rhos = [0.01, 0.05, 0.1, 0.5, 1]\n",
    "etas = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(dataset, subset):\n",
    "    train_data, test_data, train_target, test_target = load_data(dataset, subset, 'train') \n",
    "    test_data, test_target = load_data(dataset, subset, mode='test')\n",
    "    with open(os.path.join(NORMALIZER_DIR, f'{dataset}_{subset}.norm'), 'rb') as f:\n",
    "        normalizer = pickle.load(f)\n",
    "    train_data = normalizer.transform(train_data)\n",
    "    test_data = normalizer.transform(test_data)\n",
    "    return train_data, test_data, train_target, test_target\n",
    "\n",
    "def perturb_data_point(data_point, delta):\n",
    "    return data_point + delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_level_ in max_levels:\n",
    "    for model in models:\n",
    "        for dataset in datasets:\n",
    "            all_predictions = np.empty((0,))\n",
    "            all_original_predictions = np.empty((0,))\n",
    "            all_perturbed_predictions = np.empty((0,))\n",
    "            all_y_test = np.empty((0,))\n",
    "\n",
    "            for subset in datasets[dataset]:\n",
    "                X_train, X_test, y_train, y_test = loadData(dataset, subset) \n",
    "                X, y = X_train, y_train\n",
    "\n",
    "                if model == \"VAE\" or model == \"AE\":\n",
    "                    blackbox_model = torch.load(os.path.join(TARGET_MODEL_DIR, f'{model}_{dataset}_{subset}.model')).cuda(DEVICE)\n",
    "                    blackbox_model.eval()\n",
    "                    func_ = lambda x: blackbox_model.score_samples(x)\n",
    "                    score_ = func_(X)\n",
    "                    thres_ = blackbox_model.thres\n",
    "                else:\n",
    "                    with open(os.path.join(TARGET_MODEL_DIR, f'{model}_{dataset}_{subset}.model'), 'rb') as f:\n",
    "                        blackbox_model = pickle.load(f)\n",
    "                    if model == \"Whisper\":\n",
    "                        score_ = -blackbox_model.score_samples(X)\n",
    "                        thres_ = blackbox_model.threshold\n",
    "                        func_ = lambda x: -blackbox_model.score_samples(x)\n",
    "                    else:\n",
    "                        score_ = -blackbox_model.decision_function(X)\n",
    "                        thres_ = -blackbox_model.offset_\n",
    "                        func_ = lambda x: -blackbox_model.decision_function(x)\n",
    "\n",
    "                kdt_ = KITree.KITree(func_, thres_,max_level=max_level_)\n",
    "                kdt_.fit(X, score_)\n",
    "                predictions = kdt_.predict(X_test)\n",
    "                all_predictions = np.concatenate((all_predictions, predictions))\n",
    "\n",
    "                original_predictions = blackbox_model.predict(X_test)\n",
    "                if model == \"IForest\" or model == \"OCSVM\" or model == \"Whisper\":\n",
    "                    original_predictions = np.where(original_predictions == 1, 0, original_predictions)\n",
    "                    original_predictions = np.where(original_predictions == -1, 1, original_predictions)\n",
    "                all_original_predictions = np.concatenate((all_original_predictions, original_predictions))\n",
    "\n",
    "                def perturb_data_point(data_point, delta):\n",
    "                    return np.array([x + delta for x in data_point]).reshape(1, -1)\n",
    "                \n",
    "                delta = 0.01 \n",
    "                robustness_sum = 0\n",
    "                perturbed_predictions = np.empty((0,))\n",
    "                for i, data_point in enumerate(X_test):\n",
    "                    perturbed_data_point = perturb_data_point(data_point, delta)\n",
    "                    perturbed_prediction = kdt_.predict(perturbed_data_point)\n",
    "                    if np.array_equal(predictions[i], perturbed_prediction):\n",
    "                        robustness_sum += 1\n",
    "                    perturbed_predictions = np.append(perturbed_predictions, perturbed_prediction)\n",
    "                all_perturbed_predictions = np.concatenate((all_perturbed_predictions, perturbed_predictions))\n",
    "                all_y_test = np.concatenate((all_y_test, y_test))\n",
    "\n",
    "            print(\"================ Processing ( {dataset} ) dataset, using model = ( {model} )\".format(dataset=dataset, model=model), \"================\")\n",
    "\n",
    "            evaluate_and_save_results_Hyperparameters(all_y_test, all_predictions, all_original_predictions, all_perturbed_predictions, dataset, baseline=\"ours\", black_model=model, max_level=max_level_)\n",
    "print(\"============================= max_level All works are finished! =============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_beam_ in n_beams:\n",
    "    for model in models:\n",
    "        for dataset in datasets:\n",
    "            all_predictions = np.empty((0,))\n",
    "            all_original_predictions = np.empty((0,))\n",
    "            all_perturbed_predictions = np.empty((0,))\n",
    "            all_y_test = np.empty((0,))\n",
    "\n",
    "            for subset in datasets[dataset]:\n",
    "                X_train, X_test, y_train, y_test = loadData(dataset, subset) \n",
    "                X, y = X_train, y_train\n",
    "\n",
    "                if model == \"VAE\" or model == \"AE\":\n",
    "                    blackbox_model = torch.load(os.path.join(TARGET_MODEL_DIR, f'{model}_{dataset}_{subset}.model')).cuda(DEVICE)\n",
    "                    blackbox_model.eval()\n",
    "                    func_ = lambda x: blackbox_model.score_samples(x)\n",
    "                    score_ = func_(X)\n",
    "                    thres_ = blackbox_model.thres\n",
    "                else:\n",
    "                    with open(os.path.join(TARGET_MODEL_DIR, f'{model}_{dataset}_{subset}.model'), 'rb') as f:\n",
    "                        blackbox_model = pickle.load(f)\n",
    "                    if model == \"Whisper\":\n",
    "                        score_ = -blackbox_model.score_samples(X)\n",
    "                        thres_ = blackbox_model.threshold\n",
    "                        func_ = lambda x: -blackbox_model.score_samples(x)\n",
    "                    else:\n",
    "                        score_ = -blackbox_model.decision_function(X)\n",
    "                        thres_ = -blackbox_model.offset_\n",
    "                        func_ = lambda x: -blackbox_model.decision_function(x)\n",
    "\n",
    "                kdt_ = KITree.KITree(func_, thres_,n_beam=n_beam_)\n",
    "                kdt_.fit(X, score_)\n",
    "                predictions = kdt_.predict(X_test)\n",
    "                all_predictions = np.concatenate((all_predictions, predictions))\n",
    "\n",
    "                original_predictions = blackbox_model.predict(X_test)\n",
    "                if model == \"IForest\" or model == \"OCSVM\" or model == \"Whisper\":\n",
    "                    original_predictions = np.where(original_predictions == 1, 0, original_predictions)\n",
    "                    original_predictions = np.where(original_predictions == -1, 1, original_predictions)\n",
    "                all_original_predictions = np.concatenate((all_original_predictions, original_predictions))\n",
    "\n",
    "                def perturb_data_point(data_point, delta):\n",
    "                    return np.array([x + delta for x in data_point]).reshape(1, -1)\n",
    "                \n",
    "                delta = 0.01  # Define perturbation magnitude\n",
    "                robustness_sum = 0\n",
    "                perturbed_predictions = np.empty((0,))\n",
    "                for i, data_point in enumerate(X_test):\n",
    "                    perturbed_data_point = perturb_data_point(data_point, delta)\n",
    "                    perturbed_prediction = kdt_.predict(perturbed_data_point)\n",
    "                    if np.array_equal(predictions[i], perturbed_prediction):\n",
    "                        robustness_sum += 1\n",
    "                    perturbed_predictions = np.append(perturbed_predictions, perturbed_prediction)\n",
    "                all_perturbed_predictions = np.concatenate((all_perturbed_predictions, perturbed_predictions))\n",
    "                all_y_test = np.concatenate((all_y_test, y_test))\n",
    "            print(\"{dataset} _ y_test.shape = \".format(dataset=dataset))\n",
    "\n",
    "            print(\"================ Processing ( {dataset} ) dataset, using model = ( {model} )\".format(dataset=dataset, model=model), \"================\")\n",
    "\n",
    "            evaluate_and_save_results_Hyperparameters(all_y_test, all_predictions, all_original_predictions, all_perturbed_predictions, dataset, baseline=\"ours\", black_model=model, n_beam=n_beam_)\n",
    "print(\"============================= n_beams All works are finished! =============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rho_ in rhos:\n",
    "    for model in models:\n",
    "        for dataset in datasets:\n",
    "            all_predictions = np.empty((0,))\n",
    "            all_original_predictions = np.empty((0,))\n",
    "            all_perturbed_predictions = np.empty((0,))\n",
    "            all_y_test = np.empty((0,))\n",
    "\n",
    "            for subset in datasets[dataset]:\n",
    "                X_train, X_test, y_train, y_test = loadData(dataset, subset) \n",
    "                X, y = X_train, y_train\n",
    "\n",
    "                if model == \"VAE\" or model == \"AE\":\n",
    "                    blackbox_model = torch.load(os.path.join(TARGET_MODEL_DIR, f'{model}_{dataset}_{subset}.model')).cuda(DEVICE)\n",
    "                    blackbox_model.eval()\n",
    "                    func_ = lambda x: blackbox_model.score_samples(x)\n",
    "                    score_ = func_(X)\n",
    "                    thres_ = blackbox_model.thres\n",
    "                else:\n",
    "                    with open(os.path.join(TARGET_MODEL_DIR, f'{model}_{dataset}_{subset}.model'), 'rb') as f:\n",
    "                        blackbox_model = pickle.load(f)\n",
    "                    if model == \"Whisper\":\n",
    "                        score_ = -blackbox_model.score_samples(X)\n",
    "                        thres_ = blackbox_model.threshold\n",
    "                        func_ = lambda x: -blackbox_model.score_samples(x)\n",
    "                    else:\n",
    "                        score_ = -blackbox_model.decision_function(X)\n",
    "                        thres_ = -blackbox_model.offset_\n",
    "                        func_ = lambda x: -blackbox_model.decision_function(x)\n",
    "\n",
    "                kdt_ = KITree.KITree(func_, thres_,rho=rho_)\n",
    "                kdt_.fit(X, score_)\n",
    "                predictions = kdt_.predict(X_test)\n",
    "                all_predictions = np.concatenate((all_predictions, predictions))\n",
    "\n",
    "                original_predictions = blackbox_model.predict(X_test)\n",
    "                if model == \"IForest\" or model == \"OCSVM\" or model == \"Whisper\":\n",
    "                    original_predictions = np.where(original_predictions == 1, 0, original_predictions)\n",
    "                    original_predictions = np.where(original_predictions == -1, 1, original_predictions)\n",
    "                all_original_predictions = np.concatenate((all_original_predictions, original_predictions))\n",
    "\n",
    "                def perturb_data_point(data_point, delta):\n",
    "                    return np.array([x + delta for x in data_point]).reshape(1, -1)\n",
    "                \n",
    "                delta = 0.01  # Define perturbation magnitude\n",
    "                robustness_sum = 0\n",
    "                perturbed_predictions = np.empty((0,))\n",
    "                for i, data_point in enumerate(X_test):\n",
    "                    perturbed_data_point = perturb_data_point(data_point, delta)\n",
    "                    perturbed_prediction = kdt_.predict(perturbed_data_point)\n",
    "                    if np.array_equal(predictions[i], perturbed_prediction):\n",
    "                        robustness_sum += 1\n",
    "                    perturbed_predictions = np.append(perturbed_predictions, perturbed_prediction)\n",
    "                all_perturbed_predictions = np.concatenate((all_perturbed_predictions, perturbed_predictions))\n",
    "                all_y_test = np.concatenate((all_y_test, y_test))\n",
    "            print(\"{dataset} _ y_test.shape = \".format(dataset=dataset),all_y_test.shape)\n",
    "\n",
    "            print(\"================ Processing ( {dataset} ) dataset, using model = ( {model} )\".format(dataset=dataset, model=model), \"================\")\n",
    "\n",
    "\n",
    "            evaluate_and_save_results_Hyperparameters(all_y_test, all_predictions, all_original_predictions, all_perturbed_predictions, dataset, baseline=\"ours\", black_model=model, rho=rho_)\n",
    "print(\"============================= rho All works are finished! =============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eta_ in etas:\n",
    "    for model in models:\n",
    "        for dataset in datasets:\n",
    "            all_predictions = np.empty((0,))\n",
    "            all_original_predictions = np.empty((0,))\n",
    "            all_perturbed_predictions = np.empty((0,))\n",
    "            all_y_test = np.empty((0,))\n",
    "\n",
    "            for subset in datasets[dataset]:\n",
    "                X_train, X_test, y_train, y_test = loadData(dataset, subset) \n",
    "                X, y = X_train, y_train\n",
    "\n",
    "                if model == \"VAE\" or model == \"AE\":\n",
    "                    blackbox_model = torch.load(os.path.join(TARGET_MODEL_DIR, f'{model}_{dataset}_{subset}.model')).cuda(DEVICE)\n",
    "                    blackbox_model.eval()\n",
    "                    func_ = lambda x: blackbox_model.score_samples(x)\n",
    "                    score_ = func_(X)\n",
    "                    thres_ = blackbox_model.thres\n",
    "                else:\n",
    "                    with open(os.path.join(TARGET_MODEL_DIR, f'{model}_{dataset}_{subset}.model'), 'rb') as f:\n",
    "                        blackbox_model = pickle.load(f)\n",
    "                    if model == \"Whisper\":\n",
    "                        score_ = -blackbox_model.score_samples(X)\n",
    "                        thres_ = blackbox_model.threshold\n",
    "                        func_ = lambda x: -blackbox_model.score_samples(x)\n",
    "                    else:\n",
    "                        score_ = -blackbox_model.decision_function(X)\n",
    "                        thres_ = -blackbox_model.offset_\n",
    "                        func_ = lambda x: -blackbox_model.decision_function(x)\n",
    "\n",
    "                kdt_ = KITree.KITree(func_, thres_,eta=eta_)\n",
    "                kdt_.fit(X, score_)\n",
    "                predictions = kdt_.predict(X_test)\n",
    "                all_predictions = np.concatenate((all_predictions, predictions))\n",
    "\n",
    "                original_predictions = blackbox_model.predict(X_test)\n",
    "                if model == \"IForest\" or model == \"OCSVM\" or model == \"Whisper\":\n",
    "                    original_predictions = np.where(original_predictions == 1, 0, original_predictions)\n",
    "                    original_predictions = np.where(original_predictions == -1, 1, original_predictions)\n",
    "                all_original_predictions = np.concatenate((all_original_predictions, original_predictions))\n",
    "\n",
    "                def perturb_data_point(data_point, delta):\n",
    "                    return np.array([x + delta for x in data_point]).reshape(1, -1)\n",
    "                \n",
    "                delta = 0.01  # Define perturbation magnitude\n",
    "                robustness_sum = 0\n",
    "                perturbed_predictions = np.empty((0,))\n",
    "                for i, data_point in enumerate(X_test):\n",
    "                    perturbed_data_point = perturb_data_point(data_point, delta)\n",
    "                    perturbed_prediction = kdt_.predict(perturbed_data_point)\n",
    "                    if np.array_equal(predictions[i], perturbed_prediction):\n",
    "                        robustness_sum += 1\n",
    "                    perturbed_predictions = np.append(perturbed_predictions, perturbed_prediction)\n",
    "                all_perturbed_predictions = np.concatenate((all_perturbed_predictions, perturbed_predictions))\n",
    "                all_y_test = np.concatenate((all_y_test, y_test))\n",
    "            print(\"{dataset} _ y_test.shape = \".format(dataset=dataset),all_y_test.shape)\n",
    "\n",
    "            print(\"================ Processing ( {dataset} ) dataset, using model = ( {model} )\".format(dataset=dataset, model=model), \"================\")\n",
    "\n",
    "            evaluate_and_save_results_Hyperparameters(all_y_test, all_predictions, all_original_predictions, all_perturbed_predictions, dataset, baseline=\"ours\", black_model=model, eta=eta_)\n",
    "print(\"============================= eta All works are finished! =============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rho_ in rhos:\n",
    "    for model in models:\n",
    "        for dataset in datasets:\n",
    "            all_predictions = np.empty((0,))\n",
    "            all_original_predictions = np.empty((0,))\n",
    "            all_perturbed_predictions = np.empty((0,))\n",
    "            all_y_test = np.empty((0,))\n",
    "\n",
    "            for subset in datasets[dataset]:\n",
    "                X_train, X_test, y_train, y_test = loadData(dataset, subset) \n",
    "                X, y = X_train, y_train\n",
    "\n",
    "                if model == \"VAE\" or model == \"AE\":\n",
    "                    blackbox_model = torch.load(os.path.join(TARGET_MODEL_DIR, f'{model}_{dataset}_{subset}.model')).cuda(DEVICE)\n",
    "                    blackbox_model.eval()\n",
    "                    func_ = lambda x: blackbox_model.score_samples(x)\n",
    "                    score_ = func_(X)\n",
    "                    thres_ = blackbox_model.thres\n",
    "                else:\n",
    "                    with open(os.path.join(TARGET_MODEL_DIR, f'{model}_{dataset}_{subset}.model'), 'rb') as f:\n",
    "                        blackbox_model = pickle.load(f)\n",
    "                    if model == \"Whisper\":\n",
    "                        score_ = -blackbox_model.score_samples(X)\n",
    "                        thres_ = blackbox_model.threshold\n",
    "                        func_ = lambda x: -blackbox_model.score_samples(x)\n",
    "                    else:\n",
    "                        score_ = -blackbox_model.decision_function(X)\n",
    "                        thres_ = -blackbox_model.offset_\n",
    "                        func_ = lambda x: -blackbox_model.decision_function(x)\n",
    "\n",
    "                kdt_ = KITree.KITree(func_, thres_,rho=rho_)\n",
    "                kdt_.fit(X, score_)\n",
    "                predictions = kdt_.predict(X_test)\n",
    "                all_predictions = np.concatenate((all_predictions, predictions))\n",
    "\n",
    "                original_predictions = blackbox_model.predict(X_test)\n",
    "                if model == \"IForest\" or model == \"OCSVM\" or model == \"Whisper\":\n",
    "                    original_predictions = np.where(original_predictions == 1, 0, original_predictions)\n",
    "                    original_predictions = np.where(original_predictions == -1, 1, original_predictions)\n",
    "                all_original_predictions = np.concatenate((all_original_predictions, original_predictions))\n",
    "\n",
    "                def perturb_data_point(data_point, delta):\n",
    "                    return np.array([x + delta for x in data_point]).reshape(1, -1)\n",
    "                \n",
    "                delta = 0.01  # Define perturbation magnitude\n",
    "                robustness_sum = 0\n",
    "                perturbed_predictions = np.empty((0,))\n",
    "                for i, data_point in enumerate(X_test):\n",
    "                    perturbed_data_point = perturb_data_point(data_point, delta)\n",
    "                    perturbed_prediction = kdt_.predict(perturbed_data_point)\n",
    "                    if np.array_equal(predictions[i], perturbed_prediction):\n",
    "                        robustness_sum += 1\n",
    "                    perturbed_predictions = np.append(perturbed_predictions, perturbed_prediction)\n",
    "                all_perturbed_predictions = np.concatenate((all_perturbed_predictions, perturbed_predictions))\n",
    "                all_y_test = np.concatenate((all_y_test, y_test))\n",
    "            print(\"{dataset} _ y_test.shape = \".format(dataset=dataset),all_y_test.shape)\n",
    "\n",
    "            print(\"================ Processing ( {dataset} ) dataset, using model = ( {model} )\".format(dataset=dataset, model=model), \"================\")\n",
    "\n",
    "            evaluate_and_save_results_Hyperparameters(all_y_test, all_predictions, all_original_predictions, all_perturbed_predictions, dataset, baseline=\"ours\", black_model=model, rho=rho_)\n",
    "print(\"============================= rho All works are finished! =============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "data = pd.read_csv(\"./ours/Result_Baseline_Hyperparameters.csv\")\n",
    "\n",
    "metrics = [\"Fidelity\", \"precision\", \"recall\", \"Robustness\"]\n",
    "parameters = [\"max_levels\", \"n_beams\", \"rhos\", \"etas\"]\n",
    "black_models = data[\"black_model\"].unique()\n",
    "\n",
    "colors = [\"red\", \"blue\", \"green\", \"orange\", \"purple\"]\n",
    "markers = [\"o\", \"s\", \"D\", \"^\", \"v\"]\n",
    "\n",
    "for metric in metrics:\n",
    "    for i, parameter in enumerate(parameters):\n",
    "        plt.figure()\n",
    "        for j, black_model in enumerate(black_models):\n",
    "            filtered_data = data[data[\"black_model\"] == black_model]\n",
    "            plt.plot(filtered_data[parameter], filtered_data[metric], color=colors[j], marker=markers[j], label=black_model)\n",
    "        plt.xlabel(parameter)\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend()\n",
    "        plt.title(\"{} vs {}\".format(metric, parameter))\n",
    "        \n",
    "        if not os.path.exists(\"out_images\"):\n",
    "            os.makedirs(\"out_images\")\n",
    "        \n",
    "        plt.savefig(\"out_images/{}_{}.png\".format(parameter, parameter))\n",
    "        plt.close()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all images into a single image\n",
    "images = []\n",
    "for metric in metrics:\n",
    "    rows = []\n",
    "    for parameter in parameters:\n",
    "        filenames = [\"{}_vs_{}_{}.png\".format(metric, parameter, black_model) for black_model in black_models]\n",
    "        filepaths = [os.path.join(\"image\", filename) for filename in filenames]\n",
    "        images = [Image.open(filepath) for filepath in filepaths]\n",
    "        widths, heights = zip(*(i.size for i in images))\n",
    "        max_height = max(heights)\n",
    "        total_width = sum(widths)\n",
    "        combined_image = Image.new(\"RGB\", (total_width, max_height))\n",
    "        x_offset = 0\n",
    "        for image in images:\n",
    "            combined_image.paste(image, (x_offset, 0))\n",
    "            x_offset += image.size[0]\n",
    "        rows.append(combined_image)\n",
    "    widths, heights = zip(*(i.size for i in rows))\n",
    "    max_width = max(widths)\n",
    "    total_height = sum(heights)\n",
    "    combined_row = Image.new(\"RGB\", (max_width, total_height))\n",
    "    y_offset = 0\n",
    "    for row in rows:\n",
    "        combined_row.paste(row, (0, y_offset))\n",
    "        y_offset += row.size[1]\n",
    "    images.append(combined_row)\n",
    "\n",
    "# Save the combined image\n",
    "combined_image = Image.new(\"RGB\", (combined_row.size[0], total_height))\n",
    "y_offset = 0\n",
    "for image in images:\n",
    "    combined_image.paste(image, (0, y_offset))\n",
    "    y_offset += image.size[1]\n",
    "combined_image.save(\"combined_image.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
